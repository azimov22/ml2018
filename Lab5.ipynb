{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 3. Pandas, метод ближайших соседей и решающие деревья."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Otabek Azimov\n",
    "\n",
    "Student ID: 16BD02134\n",
    "\n",
    "Email: a.habibullayevich@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.neighbors\n",
    "import sklearn.ensemble as ensemble\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1: Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ответьте на вопросы о данных по авиарейсам в США.\n",
    "\n",
    "Данные: http://stat-computing.org/dataexpo/2009/2008.csv.bz2\n",
    "(обратите внимание, что распаковывать этот файл не обязательно — функция `pandas.read_csv` умеет читать из архивов автоматически)\n",
    "\n",
    "Описание: http://stat-computing.org/dataexpo/2009/the-data.html\n",
    "\n",
    "1. Какая из причин отмены рейса (`CancellationCode`) была самой частой? (расшифровки кодов можно найти в описании данных)\n",
    "2. Найдите среднее, минимальное и максимальное расстояние, пройденное самолетом.\n",
    "3. Не выглядит ли подозрительным минимальное пройденное расстояние? В какие дни и на каких рейсах оно было? Какое расстояние было пройдено этими же рейсами в другие дни?\n",
    "4. Из какого аэропорта было произведено больше всего вылетов? В каком городе он находится?\n",
    "5. Найдите для каждого аэропорта среднее время полета (`AirTime`) по всем вылетевшим из него рейсам. Какой аэропорт имеет наибольшее значение этого показателя?\n",
    "6. Найдите аэропорт, у которого наибольшая доля задержанных (`DepDelay > 0`) рейсов. Исключите при этом из рассмотрения аэропорты, из которых было отправлено меньше 1000 рейсов (используйте функцию `filter` после `groupby`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>ArrTime</th>\n",
       "      <th>CRSArrTime</th>\n",
       "      <th>FlightNum</th>\n",
       "      <th>ActualElapsedTime</th>\n",
       "      <th>...</th>\n",
       "      <th>Distance</th>\n",
       "      <th>TaxiIn</th>\n",
       "      <th>TaxiOut</th>\n",
       "      <th>Cancelled</th>\n",
       "      <th>Diverted</th>\n",
       "      <th>CarrierDelay</th>\n",
       "      <th>WeatherDelay</th>\n",
       "      <th>NASDelay</th>\n",
       "      <th>SecurityDelay</th>\n",
       "      <th>LateAircraftDelay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7009728.0</td>\n",
       "      <td>7.009728e+06</td>\n",
       "      <td>7.009728e+06</td>\n",
       "      <td>7.009728e+06</td>\n",
       "      <td>6.873482e+06</td>\n",
       "      <td>7.009728e+06</td>\n",
       "      <td>6.858079e+06</td>\n",
       "      <td>7.009728e+06</td>\n",
       "      <td>7.009728e+06</td>\n",
       "      <td>6.855029e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>7.009728e+06</td>\n",
       "      <td>6.858079e+06</td>\n",
       "      <td>6.872670e+06</td>\n",
       "      <td>7.009728e+06</td>\n",
       "      <td>7.009728e+06</td>\n",
       "      <td>1.524735e+06</td>\n",
       "      <td>1.524735e+06</td>\n",
       "      <td>1.524735e+06</td>\n",
       "      <td>1.524735e+06</td>\n",
       "      <td>1.524735e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>6.375130e+00</td>\n",
       "      <td>1.572801e+01</td>\n",
       "      <td>3.924182e+00</td>\n",
       "      <td>1.333830e+03</td>\n",
       "      <td>1.326086e+03</td>\n",
       "      <td>1.481258e+03</td>\n",
       "      <td>1.494801e+03</td>\n",
       "      <td>2.224200e+03</td>\n",
       "      <td>1.273224e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>7.263870e+02</td>\n",
       "      <td>6.860852e+00</td>\n",
       "      <td>1.645305e+01</td>\n",
       "      <td>1.960618e-02</td>\n",
       "      <td>2.463006e-03</td>\n",
       "      <td>1.577206e+01</td>\n",
       "      <td>3.039031e+00</td>\n",
       "      <td>1.716462e+01</td>\n",
       "      <td>7.497434e-02</td>\n",
       "      <td>2.077098e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.406737e+00</td>\n",
       "      <td>8.797068e+00</td>\n",
       "      <td>1.988259e+00</td>\n",
       "      <td>4.780689e+02</td>\n",
       "      <td>4.642509e+02</td>\n",
       "      <td>5.052251e+02</td>\n",
       "      <td>4.826728e+02</td>\n",
       "      <td>1.961716e+03</td>\n",
       "      <td>7.018731e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>5.621018e+02</td>\n",
       "      <td>4.933649e+00</td>\n",
       "      <td>1.133280e+01</td>\n",
       "      <td>1.386426e-01</td>\n",
       "      <td>4.956753e-02</td>\n",
       "      <td>4.009912e+01</td>\n",
       "      <td>1.950287e+01</td>\n",
       "      <td>3.189495e+01</td>\n",
       "      <td>1.837940e+00</td>\n",
       "      <td>3.925964e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>9.280000e+02</td>\n",
       "      <td>9.250000e+02</td>\n",
       "      <td>1.107000e+03</td>\n",
       "      <td>1.115000e+03</td>\n",
       "      <td>6.220000e+02</td>\n",
       "      <td>7.700000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.250000e+02</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.325000e+03</td>\n",
       "      <td>1.320000e+03</td>\n",
       "      <td>1.512000e+03</td>\n",
       "      <td>1.517000e+03</td>\n",
       "      <td>1.571000e+03</td>\n",
       "      <td>1.100000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>5.810000e+02</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.728000e+03</td>\n",
       "      <td>1.715000e+03</td>\n",
       "      <td>1.909000e+03</td>\n",
       "      <td>1.907000e+03</td>\n",
       "      <td>3.518000e+03</td>\n",
       "      <td>1.570000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>9.540000e+02</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>1.900000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.100000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.600000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>3.100000e+01</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>2.400000e+03</td>\n",
       "      <td>2.359000e+03</td>\n",
       "      <td>2.400000e+03</td>\n",
       "      <td>2.400000e+03</td>\n",
       "      <td>9.743000e+03</td>\n",
       "      <td>1.379000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>4.962000e+03</td>\n",
       "      <td>3.080000e+02</td>\n",
       "      <td>4.290000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.436000e+03</td>\n",
       "      <td>1.352000e+03</td>\n",
       "      <td>1.357000e+03</td>\n",
       "      <td>3.920000e+02</td>\n",
       "      <td>1.316000e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Year         Month    DayofMonth     DayOfWeek       DepTime  \\\n",
       "count  7009728.0  7.009728e+06  7.009728e+06  7.009728e+06  6.873482e+06   \n",
       "mean      2008.0  6.375130e+00  1.572801e+01  3.924182e+00  1.333830e+03   \n",
       "std          0.0  3.406737e+00  8.797068e+00  1.988259e+00  4.780689e+02   \n",
       "min       2008.0  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "25%       2008.0  3.000000e+00  8.000000e+00  2.000000e+00  9.280000e+02   \n",
       "50%       2008.0  6.000000e+00  1.600000e+01  4.000000e+00  1.325000e+03   \n",
       "75%       2008.0  9.000000e+00  2.300000e+01  6.000000e+00  1.728000e+03   \n",
       "max       2008.0  1.200000e+01  3.100000e+01  7.000000e+00  2.400000e+03   \n",
       "\n",
       "         CRSDepTime       ArrTime    CRSArrTime     FlightNum  \\\n",
       "count  7.009728e+06  6.858079e+06  7.009728e+06  7.009728e+06   \n",
       "mean   1.326086e+03  1.481258e+03  1.494801e+03  2.224200e+03   \n",
       "std    4.642509e+02  5.052251e+02  4.826728e+02  1.961716e+03   \n",
       "min    0.000000e+00  1.000000e+00  0.000000e+00  1.000000e+00   \n",
       "25%    9.250000e+02  1.107000e+03  1.115000e+03  6.220000e+02   \n",
       "50%    1.320000e+03  1.512000e+03  1.517000e+03  1.571000e+03   \n",
       "75%    1.715000e+03  1.909000e+03  1.907000e+03  3.518000e+03   \n",
       "max    2.359000e+03  2.400000e+03  2.400000e+03  9.743000e+03   \n",
       "\n",
       "       ActualElapsedTime        ...              Distance        TaxiIn  \\\n",
       "count       6.855029e+06        ...          7.009728e+06  6.858079e+06   \n",
       "mean        1.273224e+02        ...          7.263870e+02  6.860852e+00   \n",
       "std         7.018731e+01        ...          5.621018e+02  4.933649e+00   \n",
       "min         1.200000e+01        ...          1.100000e+01  0.000000e+00   \n",
       "25%         7.700000e+01        ...          3.250000e+02  4.000000e+00   \n",
       "50%         1.100000e+02        ...          5.810000e+02  6.000000e+00   \n",
       "75%         1.570000e+02        ...          9.540000e+02  8.000000e+00   \n",
       "max         1.379000e+03        ...          4.962000e+03  3.080000e+02   \n",
       "\n",
       "            TaxiOut     Cancelled      Diverted  CarrierDelay  WeatherDelay  \\\n",
       "count  6.872670e+06  7.009728e+06  7.009728e+06  1.524735e+06  1.524735e+06   \n",
       "mean   1.645305e+01  1.960618e-02  2.463006e-03  1.577206e+01  3.039031e+00   \n",
       "std    1.133280e+01  1.386426e-01  4.956753e-02  4.009912e+01  1.950287e+01   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    1.000000e+01  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    1.400000e+01  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%    1.900000e+01  0.000000e+00  0.000000e+00  1.600000e+01  0.000000e+00   \n",
       "max    4.290000e+02  1.000000e+00  1.000000e+00  2.436000e+03  1.352000e+03   \n",
       "\n",
       "           NASDelay  SecurityDelay  LateAircraftDelay  \n",
       "count  1.524735e+06   1.524735e+06       1.524735e+06  \n",
       "mean   1.716462e+01   7.497434e-02       2.077098e+01  \n",
       "std    3.189495e+01   1.837940e+00       3.925964e+01  \n",
       "min    0.000000e+00   0.000000e+00       0.000000e+00  \n",
       "25%    0.000000e+00   0.000000e+00       0.000000e+00  \n",
       "50%    6.000000e+00   0.000000e+00       0.000000e+00  \n",
       "75%    2.100000e+01   0.000000e+00       2.600000e+01  \n",
       "max    1.357000e+03   3.920000e+02       1.316000e+03  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"2008.csv.bz2\")\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-89395df2859a>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-89395df2859a>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    1.Какая из причин отмены рейса (CancellationCode) была самой частой? (расшифровки кодов можно найти в описании данных)\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "1.Какая из причин отмены рейса (CancellationCode) была самой частой? (расшифровки кодов можно найти в описании данных)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pd.read_csv(\"2008.csv.bz2\")\n",
    "print(DF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CC = DF['CancellationCode']\n",
    "CC.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Найдите среднее, минимальное и максимальное расстояние, пройденное самолетом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Max: \", DF.Distance.max())\n",
    "print(\"Min: \", DF.Distance.min())\n",
    "print(\"Mean: \", DF.Distance.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3. Не выглядит ли подозрительным минимальное пройденное расстояние? В какие дни и на каких рейсах оно было? Какое расстояние было пройдено этими же рейсами в другие дни?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF[DF.Distance == DF.Distance.min()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF[DF.FlightNum == 4988]['Distance'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF[DF.FlightNum == 5572]['Distance'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Из какого аэропорта было произведено больше всего вылетов? В каком городе он находится?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF[\"Origin\"].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Найдите для каждого аэропорта среднее время полета (AirTime) по всем вылетевшим из него рейсам. Какой аэропорт имеет наибольшее значение этого показателя?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.groupby(\"Origin\")['AirTime'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Max mean air time: \", DF.groupby(\"Origin\")['AirTime'].mean().argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Найдите аэропорт, у которого наибольшая доля задержанных (DepDelay > 0) рейсов. Исключите при этом из рассмотрения аэропорты, из которых было отправлено меньше 1000 рейсов (используйте функцию filter после groupby)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFGB = DF.groupby(\"Origin\")['DepDelay']\n",
    "DFGB_Filtered = DF[DF.DepDelay > 0].groupby(\"Origin\")['DepDelay']\n",
    "(DFGB_Filtered.count() / DFGB.count() * (DFGB.count() >= 1000)).argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2: метрические методы и категориальные признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все дальнейшие эксперименты предлагается проводить на данных соревнования Amazon Employee Access Challenge: https://www.kaggle.com/c/amazon-employee-access-challenge\n",
    "\n",
    "В данной задаче предлагается предсказать, будет ли одобрен запрос сотрудника на получение доступа к тому или иному ресурсу. Все признаки являются категориальными.\n",
    "\n",
    "Для удобства данные можно загрузить по ссылке: https://www.dropbox.com/s/q6fbs1vvhd5kvek/amazon.csv\n",
    "\n",
    "Сразу прочитаем данные и создадим разбиение на обучение и контроль:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('amazon.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# доля положительных примеров\n",
    "data.ACTION.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# число значений у признаков\n",
    "for col_name in data.columns:\n",
    "    print(col_name, len(data[col_name].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:, 0],test_size=0.3, random_state=241)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Реализуйте три функции расстояния на категориальных признаках, которые обсуждались на втором семинаре.\n",
    "\n",
    "Проще всего будет определить метрики как [user-defined distance](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html), после чего воспользоваться реализацией kNN из sklearn (в этом случае используйте функцию predict_proba). Можно реализовать метод k ближайших соседей и самостоятально — в этом случае учитите, что он должен возвращать оценку вероятности, то есть отношение объектов первого класса среди соседей к числу соседей).\n",
    "\n",
    "Постарайтесь уделить особое внимание эффективности кода — при реализации метрик \"в лоб\" вы можете столкнуться с очень большим временем выполнения.\n",
    "\n",
    "#### Подсчитайте для каждой из метрик качество на тестовой выборке `X_test` при числе соседей $k = 10$. Мера качества — AUC-ROC.\n",
    "\n",
    "#### Какая функция расстояния оказалась лучшей?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in data.columns:\n",
    "    print(col_name, len(data[col_name].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hash_sid = np.empty((9), dtype=dict)\n",
    "Hash_id = np.empty((9), dtype=dict)\n",
    "L = len(X_train)\n",
    "for i, feature in enumerate(X_train.columns):\n",
    "    Hash_sid[i] = {}\n",
    "    Hash_id[i] = {}\n",
    "F = X_train[feature].value_counts()\n",
    "feature_values = X_train[feature].unique()\n",
    "for x in feature_values:\n",
    "    Hash_sid[i][x] = F[x] * (F[x] - 1) / (L * (L - 1))\n",
    "    Hash_id[i][x] = math.log(F[x] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indicator_dist(x, y):\n",
    "    return (x != y).sum()\n",
    "def smoothy_indicator_dist(x, y):\n",
    "    return np.array([(x[c] != y[c]) + (x[c] == y[c]) * Hash_sid[c].get(x[c], 0) for c in range(9)]).sum()\n",
    "def importance_dist(x, y):\n",
    "    return np.array([(x[c] != y[c]) * Hash_id[c].get(x[c], 0) * Hash_id[c].get(y[c], 0) for c in range(9)]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier = sklearn.neighbors.KNeighborsClassifier(n_neighbors=10, algorithm=\"brute\", metric=indicator_dist).fit(X_train, y_train)\n",
    "print(sklearn.metrics.roc_auc_score(y_test, Classifier.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier = sklearn.neighbors.KNeighborsClassifier(n_neighbors=10, algorithm=\"brute\", metric=smoothy_indicator_dist).fit(X_train, y_train)\n",
    "print(sklearn.metrics.roc_auc_score(y_test, Classifier.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier = sklearn.neighbors.KNeighborsClassifier(n_neighbors=10, algorithm=\"brute\", metric=importance_dist).fit(X_train, y_train)\n",
    "print(sklearn.metrics.roc_auc_score(y_test, Classifier.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 (бонус). Подберите лучшее (на тестовой выборке) число соседей $k$ для каждой из функций расстояния. Какое наилучшее качество удалось получить?\n",
    "\n",
    "Для подбора можно использовать любые средства из sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeCounters(train, extractable_data, extractable_data_ans):\n",
    "        train_modified = pd.DataFrame(index=train.index)\n",
    "        for feature in train.columns:\n",
    "            vc = extractable_data[feature].value_counts()\n",
    "            vc_t = (extractable_data[feature] * extractable_data_ans).value_counts()\n",
    "            train_modified[feature + \"_counts\"] = pd.Series([vc.get(x, 0) for x in train[feature]], index=train.index),\n",
    "            train_modified[feature + \"_successes\"] = pd.Series([vc_t.get(x, 0) for x in train[feature]], index=train.index)\n",
    "    train_modified[feature + \"_cs\"] = (train_modified[feature + \"_successes\"] + 1) / (train_modified[feature + \"_counts\"] + 2)\n",
    "        return train_modified\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Реализуйте счетчики (http://blogs.technet.com/b/machinelearning/archive/2015/02/17/big-learning-made-easy-with-counts.aspx), которые заменят категориальные признаки на вещественные.\n",
    "\n",
    "А именно, каждый категориальный признак нужно заменить на три: \n",
    "1. Число `counts` объектов в обучающей выборке с таким же значением признака.\n",
    "2. Число `successes` объектов первого класса ($y = 1$) в обучающей выборке с таким же значением признака.\n",
    "3. Сглаженное отношение двух предыдущих величин: (`successes` + 1) / (`counts` + 2).\n",
    "\n",
    "Поскольку признаки, содержащие информацию о целевой переменной, могут привести к переобучению, может оказаться полезным сделать *фолдинг*: разбить обучающую выборку на $n$ частей, и для $i$-й части считать `counts` и `successes` по всем остальным частям. Для тестовой выборки используются счетчики, посчитанные по всей обучающей выборке. Реализуйте и такой вариант. Можно использовать $n = 3$.\n",
    "\n",
    "#### Посчитайте на тесте AUC-ROC метода $k$ ближайших соседей с евклидовой метрикой для выборки, где категориальные признаки заменены на счетчики. Сравните по AUC-ROC два варианта формирования выборки — с фолдингом и без. Не забудьте подобрать наилучшее число соседей $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_train = MakeCounters(X_train, X_train, y_train)\n",
    "mod_test = MakeCounters(X_test, X_train, y_train)\n",
    "k_list = np.arange(1, 20)\n",
    "auc_roc = np.empty(k_list.shape)\n",
    "for i, k in enumerate(k_list):\n",
    "    Classifier = sklearn.neighbors.KNeighborsClassifier(n_neighbors=k, algorithm=\"kd_tree\").fit(mod_train, y_train)\n",
    "    auc_roc[i] = sklearn.metrics.roc_auc_score(y_test, Classifier.predict_proba(mod_test)[:, 1])\n",
    "plt.plot(k_list, auc_roc)\n",
    "plt.show()\n",
    "print(\"BEST k: \", k_list[np.argmax(auc_roc)])\n",
    "print(\"BEST AUC-ROC: \", np.max(auc_roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = len(X_train)\n",
    "mt1 = MakeCounters(X_train[:L//3], X_train[L//3:], y_train[L//3:])\n",
    "indexes = np.append(np.arange(0, L//3), np.arange(2*L//3, L))\n",
    "mt2 = MakeCounters(X_train[L//3:2*L//3], X_train.iloc[indexes], y_train.iloc[indexes])\n",
    "mt3 = MakeCounters(X_train[2*L//3:], X_train[:2*L//3], y_train[:2*L//3])\n",
    "mt = pd.concat([mt1, mt2, mt3])\n",
    "for feature in mt.columns[np.arange(0, len(mt.columns), 3)]:\n",
    "     mt[feature] *= 3 / 2\n",
    "for feature in mt.columns[np.arange(1, len(mt.columns), 3)]:\n",
    "    mt[feature] *= 3 / 2\\\n",
    "    return mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_train = MakeCountersWithFolding(X_train, y_train)\n",
    "mod_test = MakeCounters(X_test, X_train, y_train)\n",
    "k_list = np.arange(1, 25)\n",
    "auc_roc = np.empty(k_list.shape)\n",
    "for i, k in enumerate(k_list):\n",
    "    Classifier = sklearn.neighbors.KNeighborsClassifier(n_neighbors=k, algorithm=\\\"kd_tree\\\").fit(mod_train, y_train)\n",
    "    auc_roc[i] = sklearn.metrics.roc_auc_score(y_test, Classifier.predict_proba(mod_test)[:, 1])\n",
    "plt.plot(k_list, auc_roc)\n",
    "plt.show()\n",
    "print(\"BEST k: \", k_list[np.argmax(auc_roc)])\n",
    "print(\"BEST AUC-ROC: \", np.max(auc_roc))                                                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Добавьте в исходную выборку парные признаки — то есть для каждой пары $(f_i, f_j)$, $i < j$ исходных категориальных признаков добавьте новый категориальный признак $f_{ij}$, значение которого является конкатенацией значений $f_i$ и $f_j$ (желательно через какой-нибудь специальный символ во избежание коллизий). Посчитайте счетчики для этой выборки, найдите качество метода $k$ ближайших соседей с наилучшим $k$ (с фолдингом и без)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakePairFeatures(train):\n",
    "train_modified = train.copy()\n",
    "for i, feature1 in enumerate(train.columns):\n",
    "    for feature2 in train.columns[i+1:]:\n",
    "    train_modified[feature1 + \"+\" + feature2] = train[feature1].astype(str) + \"#\" + train[feature2].astype(str)\n",
    "return train_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = MakePairFeatures(X_train), MakePairFeatures(X_test)\n",
    "mod_train_wf = MakeCountersWithFolding(train, y_train)\n",
    "mod_test_wf = MakeCounters(test, train, y_train)\n",
    "k_list = np.arange(5, 25)\n",
    "auc_roc = np.empty(k_list.shape)\n",
    "for i, k in enumerate(k_list):\n",
    "    Classifier = sklearn.neighbors.KNeighborsClassifier(n_neighbors=k, algorithm=\"kd_tree\", n_jobs = -1).fit(mod_train_wf, y_train)\n",
    "    auc_roc[i] = sklearn.metrics.roc_auc_score(y_test, Classifier.predict_proba(mod_test_wf)[:, 1])\n",
    "plt.plot(k_list, auc_roc)\n",
    "plt.show()\n",
    "print(\"BEST k: \", k_list[np.argmax(auc_roc)])\n",
    "print(\"BEST AUC-ROC: \", np.max(auc_roc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3: Решающие деревья и леса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Возьмите из предыдущей части выборку с парными признаками, преобразованную с помощью счетчиков без фолдинга. Настройте решающее дерево, подобрав оптимальные значения параметров `max_depth` и `min_samples_leaf`. Какой наилучший AUC-ROC на контроле удалось получить?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = np.arange(4, 30)\n",
    "samples_leaf = np.arange(8, 20).astype(int)\n",
    "xgrid, ygrid = np.meshgrid(depth, samples_leaf)\n",
    "zgrid = np.zeros(xgrid.shape)\n",
    "for sl in range(len(samples_leaf)):\n",
    "    for d in range(len(depth)):\n",
    "        for test_k in range(5):\n",
    "            clf = tree.DecisionTreeClassifier(max_depth=depth[d], min_samples_leaf=samples_leaf[sl])\n",
    "            clf = clf.fit(mod_train, y_train)\n",
    "            zgrid[sl][d] += sklearn.metrics.roc_auc_score(y_test, clf.predict_proba(mod_test)[:, 1])\n",
    "            zgrid[sl][d] /= 5\n",
    "plt.pcolor(xgrid, ygrid, zgrid)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=26, min_samples_leaf=13)\n",
    "clf = clf.fit(mod_train, y_train)\n",
    "print(sklearn.metrics.roc_auc_score(y_test, clf.predict_proba(mod_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Настройте случайный лес, подобрав такое число деревьев `n_estimators`, при котором ошибка выходит на асимптоту. Какое качество на тестовой выборке он дает?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_set = np.arange(1, 20)\n",
    "results = np.zeros(n_set.shape[0])\n",
    "overfitting = np.zeros(n_set.shape[0])\n",
    "for i, n in enumerate(n_set):\n",
    "    for k in range(5):\n",
    "        clf = ensemble.RandomForestClassifier(n_estimators = n, max_depth=8, min_samples_leaf=15, n_jobs = -1)\n",
    "        clf = clf.fit(mod_train_wf, y_train)\n",
    "        results[i] += sklearn.metrics.roc_auc_score(y_test, clf.predict_proba(mod_test_wf)[:, 1])\n",
    "        overfitting[i] += sklearn.metrics.roc_auc_score(y_train, clf.predict_proba(mod_train_wf)[:, 1])\n",
    "        results[i] /= 5\n",
    "        overfitting[i] /= 5\n",
    "plt.plot(n_set, results)\n",
    "plt.plot(n_set, overfitting)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ensemble.RandomForestClassifier(n_estimators = 16, max_depth=8, min_samples_leaf=15, n_jobs = -1)\n",
    "clf = clf.fit(mod_train_wf, y_train)\n",
    "print(\"FINAL RESULT: \", sklearn.metrics.roc_auc_score(y_test, clf.predict_proba(mod_test_wf)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь вы можете поделиться своими мыслями о задании."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Было сложно. Думаю нужно больше практики. И теоритического материала, который поможет изучать больше самостоятельно\n",
    "и не отстовать от лектора."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А здесь вставьте смешную картинку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "https://i.redd.it/fnyz8lt1e8o11.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А здесь посоветуйте преподавателям хороший фильм или сериал."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Всё ещё Элис"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
